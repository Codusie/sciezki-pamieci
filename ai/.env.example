# Bydgoszcz LLM Tour Guide API
# ============================================
# Flask Configuration
DEBUG=false
FLASK_ENV=development

# ============================================
# LLM PROVIDER SELECTION
# ============================================
# Choose ONE of these providers: openai, gemini, claude, ollama
# LLM_PROVIDER=openai
LLM_PROVIDER=gemini
# LLM_PROVIDER=claude
# LLM_PROVIDER=ollama

# ============================================
# OPENAI / GPT MODELS
# ============================================
# Only needed if LLM_PROVIDER=openai
# Models: gpt-3.5-turbo, gpt-4, gpt-4-turbo, etc.
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o

# ============================================
# GOOGLE GEMINI MODELS
# ============================================
# Only needed if LLM_PROVIDER=gemini
# Get API key from: https://makersuite.google.com/app/apikey
# Models: gemini-pro, gemini-1.5-pro, etc.
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-2.5-flash

# ============================================
# ANTHROPIC CLAUDE MODELS
# ============================================
# Only needed if LLM_PROVIDER=claude
# Get API key from: https://console.anthropic.com
# Models: claude-3-opus, claude-3-sonnet, claude-3-haiku, etc.
CLAUDE_API_KEY=your_claude_api_key_here

# ============================================
# OLLAMA - LOCAL MODEL
# ============================================
# Only needed if LLM_PROVIDER=ollama
# Ollama must be running locally. Download from: https://ollama.ai
# Models: llama2, mistral, neural-chat, etc.
# Start Ollama with: ollama serve
OLLAMA_BASE_URL=http://localhost:11434

# ============================================
# COMMON LLM SETTINGS
# ============================================
LLM_MODEL=gemini-2.5-flash
MAX_TOKENS=1000
TEMPERATURE=0.2
